{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9a90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e6e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d09a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151644, 77091]\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.encode(\"<|im_start|>assistant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b61830aa1b4bd098fac3fe0a918229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2VLForConditionalGeneration(\n",
       "  (model): Qwen2VLModel(\n",
       "    (visual): Qwen2VisionTransformerPretrainedModel(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "      )\n",
       "      (rotary_pos_emb): VisionRotaryEmbedding()\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x Qwen2VLVisionBlock(\n",
       "          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): VisionAttention(\n",
       "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (mlp): VisionMlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): QuickGELUActivation()\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (merger): PatchMerger(\n",
       "        (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1536, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (language_model): Qwen2VLTextModel(\n",
       "      (embed_tokens): Embedding(151936, 1536)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen2VLDecoderLayer(\n",
       "          (self_attn): Qwen2VLAttention(\n",
       "            (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "            (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    dtype=\"float16\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2243976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2VLConfig {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"float16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2_vl\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"rope_type\": \"default\",\n",
      "    \"type\": \"default\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"text_config\": {\n",
      "    \"architectures\": [\n",
      "      \"Qwen2VLForConditionalGeneration\"\n",
      "    ],\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bos_token_id\": 151643,\n",
      "    \"dtype\": \"float16\",\n",
      "    \"eos_token_id\": 151645,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 1536,\n",
      "    \"image_token_id\": null,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 8960,\n",
      "    \"layer_types\": [\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\"\n",
      "    ],\n",
      "    \"max_position_embeddings\": 32768,\n",
      "    \"max_window_layers\": 28,\n",
      "    \"model_type\": \"qwen2_vl_text\",\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_hidden_layers\": 28,\n",
      "    \"num_key_value_heads\": 2,\n",
      "    \"rms_norm_eps\": 1e-06,\n",
      "    \"rope_scaling\": {\n",
      "      \"mrope_section\": [\n",
      "        16,\n",
      "        24,\n",
      "        24\n",
      "      ],\n",
      "      \"rope_type\": \"default\",\n",
      "      \"type\": \"default\"\n",
      "    },\n",
      "    \"rope_theta\": 1000000.0,\n",
      "    \"sliding_window\": null,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"use_cache\": true,\n",
      "    \"use_sliding_window\": false,\n",
      "    \"video_token_id\": null,\n",
      "    \"vision_end_token_id\": 151653,\n",
      "    \"vision_start_token_id\": 151652,\n",
      "    \"vision_token_id\": 151654,\n",
      "    \"vocab_size\": 151936\n",
      "  },\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"depth\": 32,\n",
      "    \"dtype\": \"float16\",\n",
      "    \"embed_dim\": 1280,\n",
      "    \"hidden_act\": \"quick_gelu\",\n",
      "    \"hidden_size\": 1536,\n",
      "    \"in_channels\": 3,\n",
      "    \"in_chans\": 3,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"mlp_ratio\": 4,\n",
      "    \"model_type\": \"qwen2_vl\",\n",
      "    \"num_heads\": 16,\n",
      "    \"patch_size\": 14,\n",
      "    \"spatial_merge_size\": 2,\n",
      "    \"spatial_patch_size\": 14,\n",
      "    \"temporal_patch_size\": 2\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5cc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,630,080 || all params: 2,223,615,680 || trainable%: 0.6579\n"
     ]
    }
   ],
   "source": [
    "target_modules = [\n",
    "    # text attention\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "    # text MLP\n",
    "    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    # vision attention\n",
    "    \"qkv\", \"proj\",\n",
    "    # vision MLP\n",
    "    \"fc1\", \"fc2\",\n",
    "    # merger: target only the Linear leaves (avoid the container)\n",
    "    \"visual.merger.mlp.0\",\n",
    "    \"visual.merger.mlp.2\",\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    target_modules=target_modules,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7e5164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'latex_formula', 'category'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "raw_dataset = load_from_disk(\"datasets/latex80m_en_10k/\")\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e00b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=191x22>,\n",
       " 'latex_formula': '\\\\[x_{\\\\boldsymbol{\\\\alpha}}\\\\coloneqq x_{\\\\alpha_{1}}\\\\cdots x_{\\\\alpha_{\\\\ell}}\\\\]',\n",
       " 'category': 'inline'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74827620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=241x72>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, answer = raw_dataset[0][\"image\"], raw_dataset[0][\"latex_formula\"]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3722d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\[\\pi_{q}(n)=\\frac{1}{n}\\sum_{d|n}\\mu(d)q^{\\frac{n}{d}},\\]\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1198bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3167, 3114, 279, 2661, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'pixel_values': tensor([[ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ..., -1.0252, -1.0394, -1.0821],\n",
       "        ...,\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459]]), 'image_grid_thw': tensor([[ 1,  6, 18]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [msg],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "print(len(inputs[\"input_ids\"][0]))\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fec0a6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nTranscribe the given image to LaTeX.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "918a3044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 3167, 3114, 279, 2661, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [msg],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3ab92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nTranscribe the given image to LaTeX.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ddf8b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3167, 3114, 279, 2661, 2168, 311, 97913, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer(\"Transcribe the given image to LaTeX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e254b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16253\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"datasets/2.jpg\")\n",
    "\n",
    "msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [msg],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "print(len(inputs[\"input_ids\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be3ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3167, 3114, 279, 2661, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198, 59, 26056, 2493, 15159, 80, 25547, 77, 11730, 59, 37018, 90, 16, 15170, 77, 11035, 1242, 15159, 67, 91, 77, 11035, 15128, 1500, 8, 80, 61, 35702, 37018, 91362, 15170, 67, 38154, 59, 60, 151645, 198]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'pixel_values': tensor([[ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ..., -1.0252, -1.0394, -1.0821],\n",
       "        ...,\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
       "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459]]), 'image_grid_thw': tensor([[ 1,  6, 18]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, answer = raw_dataset[0][\"image\"], raw_dataset[0][\"latex_formula\"]\n",
    "\n",
    "msg = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": answer}],\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [msg],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=False,\n",
    ")\n",
    "\n",
    "print(len(inputs[\"input_ids\"][0]))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "128cd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<|vision_start|><|image_pad|><|vision_end|>Transcribe the given image to LaTeX.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\\[\\pi_{q}(n)=\\frac{1}{n}\\sum_{d|n}\\mu(d)q^{\\frac{n}{d}},\\]<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(processor.apply_chat_template(\n",
    "    [msg],\n",
    ")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b1f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids, attention_mask, pixel_values, image_grid_thw, "
     ]
    }
   ],
   "source": [
    "for key in inputs:\n",
    "    print(key, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1e78526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '<|im_end|>',\n",
       " 'pad_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<|object_ref_start|>',\n",
       "  '<|object_ref_end|>',\n",
       "  '<|box_start|>',\n",
       "  '<|box_end|>',\n",
       "  '<|quad_start|>',\n",
       "  '<|quad_end|>',\n",
       "  '<|vision_start|>',\n",
       "  '<|vision_end|>',\n",
       "  '<|vision_pad|>',\n",
       "  '<|image_pad|>',\n",
       "  '<|video_pad|>']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f9a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151644, 77091]\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.encode(\"<|im_start|>assistant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eb3407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151644,\n",
       " 8948,\n",
       " 198,\n",
       " 2610,\n",
       " 525,\n",
       " 264,\n",
       " 10950,\n",
       " 17847,\n",
       " 13,\n",
       " 151645,\n",
       " 198,\n",
       " 151644,\n",
       " 872,\n",
       " 198,\n",
       " 151652,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151655,\n",
       " 151653,\n",
       " 3167,\n",
       " 3114,\n",
       " 279,\n",
       " 2661,\n",
       " 2168,\n",
       " 311,\n",
       " 97913,\n",
       " 13,\n",
       " 151645,\n",
       " 198,\n",
       " 151644,\n",
       " 77091,\n",
       " 198,\n",
       " 59,\n",
       " 26056,\n",
       " 2493,\n",
       " 15159,\n",
       " 80,\n",
       " 25547,\n",
       " 77,\n",
       " 11730,\n",
       " 59,\n",
       " 37018,\n",
       " 90,\n",
       " 16,\n",
       " 15170,\n",
       " 77,\n",
       " 11035,\n",
       " 1242,\n",
       " 15159,\n",
       " 67,\n",
       " 91,\n",
       " 77,\n",
       " 11035,\n",
       " 15128,\n",
       " 1500,\n",
       " 8,\n",
       " 80,\n",
       " 61,\n",
       " 35702,\n",
       " 37018,\n",
       " 91362,\n",
       " 15170,\n",
       " 67,\n",
       " 38154,\n",
       " 59,\n",
       " 60,\n",
       " 151645,\n",
       " 198]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = inputs[\"input_ids\"][0]\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7df4a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Transcribe the given image to LaTeX.<|im_end|>\\n<|im_start|>assistant\\n\\\\[\\\\pi_{q}(n)=\\\\frac{1}{n}\\\\sum_{d|n}\\\\mu(d)q^{\\\\frac{n}{d}},\\\\]<|im_end|>\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, answer = raw_dataset[0][\"image\"], raw_dataset[0][\"latex_formula\"]\n",
    "\n",
    "prompt_msg = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "full_msg = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": answer}],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt_input_ids = processor.apply_chat_template(\n",
    "    prompt_msg,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    ")[\"input_ids\"]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [full_msg],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=False,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "labels = inputs[\"input_ids\"][0][:]\n",
    "labels[: len(prompt_input_ids)] = -100\n",
    "\n",
    "unmasked_ids = inputs[\"input_ids\"][0][len(prompt_input_ids) :]\n",
    "processor.tokenizer.decode(unmasked_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af485d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3167, 3114, 279, 2661, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198]]\n"
     ]
    }
   ],
   "source": [
    "prompt_input_ids = processor.apply_chat_template(\n",
    "    [prompt_msg],\n",
    "    tokenize=True,\n",
    "    # return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "print(prompt_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5537b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c34f631a3344fd691d93355e1cf592f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336b46fe698d4c118cc84ebba774fedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"parquet\", data_files=\"./datasets/latex80m_en_10k.parquet\")\n",
    "\n",
    "raw_datasets[\"train\"] = load_dataset(\"parquet\", data_files=\"./datasets/latex80m_en_10k.parquet\", split=\"train[:90%]\")\n",
    "raw_datasets[\"validation\"] = load_dataset(\"parquet\", data_files=\"./datasets/latex80m_en_10k.parquet\", split=\"train[90%:]\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", use_fast=True)\n",
    "\n",
    "\n",
    "def build_messages(image, latex_formula):\n",
    "    user = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": \"Transcribe the given image to LaTeX.\"}\n",
    "        ]\n",
    "    }\n",
    "    assistant = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": latex_formula}]\n",
    "    }\n",
    "    return [user], [user, assistant]\n",
    "\n",
    "def pre_process(example):\n",
    "    image = example[\"image\"]\n",
    "    answer = example[\"latex_formula\"]\n",
    "    \n",
    "    user_only_msgs, full_msgs = build_messages(image, answer)\n",
    "    \n",
    "    prompt_input_ids = processor.apply_chat_template(\n",
    "        user_only_msgs,\n",
    "        tokenize=True,\n",
    "        return_dict=False,\n",
    "        add_generation_prompt=True,\n",
    "    )[0]\n",
    "    prompt_len = len(prompt_input_ids)\n",
    "    full_input_ids = processor.apply_chat_template(\n",
    "        full_msgs,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        add_generation_prompt=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    labels = full_input_ids[\"input_ids\"][0].clone()\n",
    "    labels[:prompt_len] = -100\n",
    "    return {\n",
    "        **full_input_ids,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "raw_datasets = raw_datasets.map(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21beb023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'latex_formula', 'category', 'input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw', 'labels'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062a59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 78045, 87, 15159, 59, 14824, 18785, 35702, 7141, 3417, 59, 2074, 603, 27579, 856, 15159, 59, 7141, 15159, 16, 3417, 59, 4385, 2412, 856, 15159, 59, 7141, 15159, 59, 613, 3417, 59, 60, 151645, 198]\n",
      "35\n",
      "[78045, 87, 15159, 59, 14824, 18785, 35702, 7141, 3417, 59, 2074, 603, 27579, 856, 15159, 59, 7141, 15159, 16, 3417, 59, 4385, 2412, 856, 15159, 59, 7141, 15159, 59, 613, 3417, 59, 60, 151645, 198]\n",
      "\\[x_{\\boldsymbol{\\alpha}}\\coloneqq x_{\\alpha_{1}}\\cdots x_{\\alpha_{\\ell}}\\]<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = raw_datasets[\"train\"][3]\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "labels = inputs[\"labels\"]\n",
    "print(labels)\n",
    "\n",
    "last_index = len(labels) - 1 - labels[::-1].index(-100)\n",
    "print(last_index)\n",
    "\n",
    "unmasked_ids = labels[last_index + 1:]\n",
    "print(unmasked_ids)\n",
    "\n",
    "print(processor.decode(unmasked_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc19aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.index(-100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "750c550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3167, 3114, 279, 2661, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198], [151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 3167, 3114, 279, 264, 44953, 35834, 44953, 2577, 41856, 2218, 823, 264, 823, 2168, 311, 97913, 13, 151645, 198, 151644, 77091, 198]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'pixel_values': tensor([[ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
      "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
      "        [ 1.9303,  1.9303,  1.9303,  ..., -1.0252, -1.0394, -1.0821],\n",
      "        ...,\n",
      "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
      "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
      "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459]]), 'image_grid_thw': tensor([[ 1,  6, 18]])}\n"
     ]
    }
   ],
   "source": [
    "msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Transcribe the given image to LaTeX.\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "msg2 = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Transcribe the aefeafaefeaf ae faef aef image to LaTeX.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    [[msg], [msg2]],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    add_generation_prompt=True,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac89e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1])\n",
      "tensor([ 3, -1,  2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([\n",
    "    [0, 1, 0, 2],\n",
    "    [0, 0, 0, 0],\n",
    "    [3, 0, 4, 0]\n",
    "])\n",
    "\n",
    "# Flip horizontally, find first non-zero from the right\n",
    "rightmost = (x != 0).int().fliplr().argmax(dim=1)\n",
    "print(rightmost)\n",
    "\n",
    "# If a row has *no* non-zero, argmax returns 0 incorrectly — fix that:\n",
    "mask = (x != 0).any(dim=1)\n",
    "rightmost[mask] = x.shape[1] - 1 - rightmost[mask]\n",
    "rightmost[~mask] = -1  # use -1 for \"no non-zero\"\n",
    "\n",
    "print(rightmost)\n",
    "# tensor([3, -1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b5b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
